deepspeed: "scripts/deepspeed/zero3.json"

do_train: True

per_device_train_batch_size: 4
per_device_eval_batch_size: 1

dataloader_num_workers: 4
dataloader_pin_memory: True

gradient_accumulation_steps: 4

fp16: False
bf16: True

num_train_epochs: 2
warmup_ratio: 0.1
learning_rate: 3e-4
lr_scheduler_type: "cosine"

seed: 42

eval_strategy: "no" # ['no', 'steps', 'epoch']

save_strategy: "epoch" # ['no', 'steps', 'epoch']
save_steps: 5
save_total_limit: -1

log_level: "info"
logging_strategy: "steps"
logging_steps: 5


report_to: "wandb" # wandb/tensorboard