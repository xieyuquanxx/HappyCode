deepspeed: "scripts/deepspeed/zero3.json"

per_device_train_batch_size: 1
per_device_eval_batch_size: 1

dataloader_num_workers: 4
dataloader_pin_memory: False

gradient_accumulation_steps: 1

fp16: False
bf16: True

# lora:
#   lora_enable: False
#   lora_r: 128
#   lora_alpha: 256
#   lora_dropout: 0.05
#   lora_bias: "none"

num_train_epochs: 5
warmup_ratio: 0.1
learning_rate: 3e-4
lr_scheduler_type: "cosine"

seed: 42

eval_strategy: "no" # ['no', 'steps', 'epoch']

save_strategy: "steps" # ['no', 'steps', 'epoch']
save_total_limit: 10

log_level: "info"
logging_strategy: "steps"
logging_steps: 1


report_to: "wandb"